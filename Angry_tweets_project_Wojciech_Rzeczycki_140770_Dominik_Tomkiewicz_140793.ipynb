{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923fbb3e",
   "metadata": {},
   "source": [
    "# Angry tweets\n",
    "## Dominik Tomkiewicz 140793\n",
    "## Wojciech Rzeczycki 140770\n",
    "\n",
    "W ramach drugiego projektu z Zaawansowanej eksploracji danych przygotowano model predykcji klasyfikacji dla sentymentu tweetów.\n",
    "Analizie poddany został zbiór danych kilku tysięcy tweetów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d9ad0",
   "metadata": {},
   "source": [
    "# 1. Wykorzystane biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d81d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6dacce",
   "metadata": {},
   "source": [
    "# 2. Pobranie danych\n",
    "\n",
    "Dane składają się z wpisów o tweetach: sentymentu użytkownika (pozytywna/negatywna/neutralna) oraz jego wpisu. Wszystkie słowa potratkowano jako stringi, dodatkowo ze zbioru danych testowych usunięto wartości puste występujące na końcu pliku.\n",
    "\n",
    "Stworzono algorytm, który klasyfikuje tweety do odpowiedniego sentymentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb38bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = ['negative', 'positive', 'neutral']\n",
    "stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', \n",
    "              'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', \n",
    "              'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', \n",
    "              'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', \n",
    "              'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', \n",
    "              'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', \n",
    "              'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', \n",
    "              'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', \n",
    "              'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', \n",
    "              'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "\n",
    "tweets = pd.read_csv(\"train.csv\", header=0, sep=',', dtype = str)\n",
    "\n",
    "tmp = np.random.rand(len(tweets)) < 0.75\n",
    "angryTweetsTrain = tweets[tmp]\n",
    "angryTweetsTest = tweets[~tmp]\n",
    "\n",
    "angryTweetsTrainData = []\n",
    "angryTweetsTrainLabel = []\n",
    "\n",
    "angryTweetsTestData = []\n",
    "angryTweetsTestLabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2880aa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>636276311560859648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If you're not already signed up to test my iOS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Category  \\\n",
       "0  635769805279248384  negative   \n",
       "1  635930169241374720   neutral   \n",
       "2  635950258682523648   neutral   \n",
       "3  636030803433009153  negative   \n",
       "4  636100906224848896  positive   \n",
       "6  636276311560859648   neutral   \n",
       "\n",
       "                                               Tweet  \n",
       "0                                      Not Available  \n",
       "1  IOS 9 App Transport Security. Mm need to check...  \n",
       "2  Mar if you have an iOS device, you should down...  \n",
       "3  @jimmie_vanagon my phone does not run on lates...  \n",
       "4  Not sure how to start your publication on iOS?...  \n",
       "6  If you're not already signed up to test my iOS...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angryTweetsTrain.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c8a13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>636176272947744772</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Two Dollar Tuesday is here with Forklift 2, Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>636302400546975744</td>\n",
       "      <td>neutral</td>\n",
       "      <td>YouTube Gaming Officially Launches On Web, And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>636484190050119681</td>\n",
       "      <td>positive</td>\n",
       "      <td>Today @YouTubeGaming launches, with apps for i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>636828460820729856</td>\n",
       "      <td>positive</td>\n",
       "      <td>#CrossSkyHigh is going IOS #saturday. For now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>637333676099932160</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Huawei Watch Pre-Order Suggests Android Wear C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>638206033639292932</td>\n",
       "      <td>positive</td>\n",
       "      <td>@tim_cook loving my new iPhone 6 from T-Mobile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id  Category  \\\n",
       "5   636176272947744772   neutral   \n",
       "7   636302400546975744   neutral   \n",
       "11  636484190050119681  positive   \n",
       "14  636828460820729856  positive   \n",
       "24  637333676099932160   neutral   \n",
       "33  638206033639292932  positive   \n",
       "\n",
       "                                                Tweet  \n",
       "5   Two Dollar Tuesday is here with Forklift 2, Qu...  \n",
       "7   YouTube Gaming Officially Launches On Web, And...  \n",
       "11  Today @YouTubeGaming launches, with apps for i...  \n",
       "14  #CrossSkyHigh is going IOS #saturday. For now ...  \n",
       "24  Huawei Watch Pre-Order Suggests Android Wear C...  \n",
       "33  @tim_cook loving my new iPhone 6 from T-Mobile...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angryTweetsTest.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa24c83",
   "metadata": {},
   "source": [
    "# 3. Przetwarzanie tweetów\n",
    "\n",
    "Dla każdego wpisu w listach treningowej i testowej dokonujemy transformacji danych:\n",
    "\n",
    "- usuwamy słowa zaczynające się od symbolu @ (służące do oznaczenia użytkownika, co nie dostarcza informacji na temat sentymentu),\n",
    "\n",
    "- zamieniamy kody znaków na znaki,\n",
    "\n",
    "- usuwamy słowa znajdujące się w zmiennej stop_words (słowa łączące wypowiedzi, nie dostarczające przydatnych informacji),\n",
    "\n",
    "- po oczyszczeniu danych dodajemy do listy sentyment i zawartość tweeta (co posłuży jego klasyfikacji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ce0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub('&nbsp;', ' ', text)\n",
    "    text = re.sub('&lt;', '<', text)\n",
    "    text = re.sub('&gt;', '>', text)\n",
    "    text = re.sub('&amp;', '&', text)\n",
    "    text = re.sub('&pound;', u'£', text)\n",
    "    text = re.sub('&euro;', u'€', text)\n",
    "    text = re.sub('&copy;', u'©', text)\n",
    "    text = re.sub('&reg;', u'®', text)\n",
    "    return text\n",
    "\n",
    "for index, tweet in angryTweetsTrain.iterrows():\n",
    "    try:\n",
    "        tweet[2] = replace(tweet[2])\n",
    "        tweet_words = tweet[2].split()\n",
    "        cleaned_words  = [word for word in tweet_words if word.lower() not in stop_words]\n",
    "        tweet[2] = ' '.join(cleaned_words)\n",
    "        angryTweetsTrainData.append(tweet[2])\n",
    "        angryTweetsTrainLabel.append(tweet[1])\n",
    "    except:\n",
    "        print(type(tweet))\n",
    "            \n",
    "for index, tweet in angryTweetsTest.iterrows():\n",
    "    try:\n",
    "        tweet[2] = replace(tweet[2])\n",
    "        tweet_words = tweet[2].split()\n",
    "        cleaned_words  = [word for word in tweet_words if word.lower() not in stop_words]\n",
    "        tweet[2] = ' '.join(cleaned_words)\n",
    "        angryTweetsTestData.append(tweet[2])\n",
    "        angryTweetsTestLabel.append(tweet[1])\n",
    "    except:\n",
    "            print(type(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c08bee",
   "metadata": {},
   "source": [
    "# 4. Przypisanie wag słowom\n",
    "\n",
    "Dla tweetów cechy, które pomogą w klasyfikacji to słowa, które w nich występują, a ich wagi to częstotliwość ich występowania w tweetach.\n",
    "\n",
    "Za pomocą metody TfidfVectorizer transformujemy dane wejściowe w wektory dla klasyfikatora ustawiając odpowiednie parametry:\n",
    "\n",
    "- min_df - odrzucane są słowa występujące w mniej niż określonej liczbie wpisów,\n",
    "\n",
    "- max_df - odrzuca słowa pojawiające się w określonym ułamku dokumentów,\n",
    "\n",
    "- sublinear_tf i use_idf - używanie sublinear weighting i wagowania IDF.\n",
    "\n",
    "Za pomocą funkcji fit_transform zostanie stworzony słownik słowo-waga. Funkcja transform transformuje dane do wersji słownikowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b34e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 4,\n",
    "                             max_df = 0.95,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "tweets_train_vectors = vectorizer.fit_transform(angryTweetsTrainData)\n",
    "tweets_test_vectors = vectorizer.transform(angryTweetsTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bedd9",
   "metadata": {},
   "source": [
    "# 5. Trening\n",
    "\n",
    "Po analizie możliwości klasyfikatorów dostarczonych przez Scikit-learn zdecydowano się na wykorzystanie algorytmu Naiwnego Bayesa. Poniżej kod trenujący klasyfikator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2abb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_NB = MultinomialNB()\n",
    "classifier_NB.fit(tweets_train_vectors, angryTweetsTrainLabel)\n",
    "prediction_NB=classifier_NB.predict(tweets_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6ca023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla naiwnego Bayesa\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.06      0.11       236\n",
      "     neutral       0.45      0.33      0.38       533\n",
      "    positive       0.58      0.86      0.69       723\n",
      "\n",
      "    accuracy                           0.54      1492\n",
      "   macro avg       0.53      0.42      0.39      1492\n",
      "weighted avg       0.53      0.54      0.49      1492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Wyniki dla naiwnego Bayesa\")\n",
    "print(classification_report(angryTweetsTestLabel, prediction_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888dc9e",
   "metadata": {},
   "source": [
    "# 6. Testowanie\n",
    "\n",
    "Poniżej kod testujący działanie klasyfikatora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8547e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsTrain = pd.read_csv(\"train.csv\", header = 0, sep=',', dtype = str)\n",
    "tweetsTest = pd.read_csv(\"test.csv\", header = 0, sep=',', dtype = str).dropna()\n",
    "\n",
    "tweetsTrainData = []\n",
    "tweetsTrainLabel = []\n",
    "\n",
    "tweetsTestId = []\n",
    "tweetsTestData = []\n",
    "tweetsTestLabel = []\n",
    "            \n",
    "for index, tweet in tweetsTrain.iterrows():\n",
    "    try:\n",
    "        tweet[2] = replace(tweet[2])\n",
    "        tweet_words = tweet[2].split()\n",
    "        cleaned_words  = [word for word in tweet_words if word.lower() not in stop_words]\n",
    "        tweet[2] = ' '.join(cleaned_words)\n",
    "        tweetsTrainData.append(tweet[2])\n",
    "        tweetsTrainLabel.append(tweet[1])\n",
    "    except:\n",
    "            print(type(tweet))\n",
    "    \n",
    "for index, tweet in tweetsTest.iterrows():\n",
    "    try:\n",
    "        tweet[1] = replace(tweet[1])\n",
    "        tweet_words = tweet[1].split()\n",
    "        cleaned_words  = [word for word in tweet_words if word.lower() not in stop_words]\n",
    "        tweet[1] = ' '.join(cleaned_words)\n",
    "        tweetsTestData.append(tweet[1])\n",
    "        tweetsTestId.append(tweet[0])\n",
    "    except:\n",
    "            print(type(tweet))\n",
    "    \n",
    "vectorizer = TfidfVectorizer(min_df = 4,\n",
    "                             max_df = 0.95,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(tweetsTrainData)\n",
    "test_vectors = vectorizer.transform(tweetsTestData)\n",
    "\n",
    "classifier_NB_test = MultinomialNB()\n",
    "classifier_NB_test.fit(train_vectors, tweetsTrainLabel)\n",
    "prediction_NB_test=classifier_NB_test.predict(test_vectors)\n",
    "\n",
    "header = {'Id': tweetsTestId, 'Category': prediction_NB_test}\n",
    "result = pd.DataFrame(data = header)\n",
    "result.to_csv('result.csv', sep = ',', columns=['Id', 'Category'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109ecc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
